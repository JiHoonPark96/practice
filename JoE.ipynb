{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec652384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTDIR = c:\\Users\\starw\\.vscode\\practice\\gapA_outputs_v3\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "import os, json, time, warnings, math\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, Any, Tuple, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LassoCV, LogisticRegression, HuberRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---- prevent nested threading (VERY IMPORTANT) ----\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "OUTDIR = \"./gapA_outputs_v3\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "print(\"OUTDIR =\", os.path.abspath(OUTDIR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8446e348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(RUN_MAIN_MC=True, MAIN_REPS=400, N=1000, P=50, THETA0=0.5, K_FOLDS=5, SEED=42, WINSOR_LEVELS=(0.0, 0.005, 0.01, 0.025, 0.05), RUN_LASSO=True, RUN_RF=True, RF_NEST=300, RF_MAXDEPTH=8, RUN_ROBUST_NUISANCE=True, STUDENT_T_DF_MAIN=3, STUDENT_T_DF_SWEEP=10, CONTAM_EPS=0.05, CONTAM_SCALE=25.0, RUN_APPX_EXPENSIVE=True, APPX_REPS=200, EXPENSIVE_WINSOR_LEVELS=(0.01, 0.05), EXPENSIVE_DGPS=('contamination', 'student_t_df3'), EXPENSIVE_LEARNERS=('lasso_logit', 'rf_rf'), N_JOBS=-1, BATCH_SIZE=8, SAVE_TABLES=True, SAVE_FIGS=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [code]\n",
    "@dataclass\n",
    "class Config:\n",
    "    # ========== Main Monte Carlo ==========\n",
    "    RUN_MAIN_MC: bool = True\n",
    "    MAIN_REPS: int = 400          # 1000은 과하니 400으로 \"안정성+현실성\" 타협\n",
    "    N: int = 1000\n",
    "    P: int = 50\n",
    "    THETA0: float = 0.5\n",
    "    \n",
    "    # DML\n",
    "    K_FOLDS: int = 5\n",
    "    SEED: int = 42\n",
    "    \n",
    "    # winsor levels for score-winsor sweep (cheap)\n",
    "    WINSOR_LEVELS: Tuple[float, ...] = (0.0, 0.005, 0.01, 0.025, 0.05)\n",
    "\n",
    "    # ========== Learners ==========\n",
    "    RUN_LASSO: bool = True\n",
    "    RUN_RF: bool = True\n",
    "    RF_NEST: int = 300\n",
    "    RF_MAXDEPTH: int = 8\n",
    "    RUN_ROBUST_NUISANCE: bool = True   # Huber nuisance\n",
    "    \n",
    "    # ========== Tail / contamination knobs ==========\n",
    "    STUDENT_T_DF_MAIN: int = 3\n",
    "    STUDENT_T_DF_SWEEP: int = 10       # (추가3) tail severity sweep\n",
    "    CONTAM_EPS: float = 0.05\n",
    "    CONTAM_SCALE: float = 25.0\n",
    "    \n",
    "    # ========== Appendix (Expensive strategies) ==========\n",
    "    RUN_APPX_EXPENSIVE: bool = True\n",
    "    APPX_REPS: int = 200               # expensive는 reps를 줄여도 방어용으론 충분\n",
    "    EXPENSIVE_WINSOR_LEVELS: Tuple[float, ...] = (0.01, 0.05)\n",
    "    EXPENSIVE_DGPS: Tuple[str, ...] = (\"contamination\", \"student_t_df3\")  # 핵심 꼬리 환경 2개만\n",
    "    EXPENSIVE_LEARNERS: Tuple[str, ...] = (\"lasso_logit\", \"rf_rf\")        # 대표 2개만\n",
    "    \n",
    "    # ========== Parallel ==========\n",
    "    N_JOBS: int = -1\n",
    "    BATCH_SIZE: int = 8\n",
    "    \n",
    "    # ========== Output ==========\n",
    "    SAVE_TABLES: bool = True\n",
    "    SAVE_FIGS: bool = True\n",
    "\n",
    "CFG = Config()\n",
    "CFG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8940dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "def winsorize_array(x: np.ndarray, level: float) -> np.ndarray:\n",
    "    if level <= 0:\n",
    "        return x.copy()\n",
    "    lo = np.quantile(x, level)\n",
    "    hi = np.quantile(x, 1 - level)\n",
    "    return np.clip(x, lo, hi)\n",
    "\n",
    "def winsorize_matrix_by_col(X: np.ndarray, level: float) -> np.ndarray:\n",
    "    if level <= 0:\n",
    "        return X.copy()\n",
    "    Xw = X.copy()\n",
    "    for j in range(Xw.shape[1]):\n",
    "        Xw[:, j] = winsorize_array(Xw[:, j], level)\n",
    "    return Xw\n",
    "\n",
    "def foldwise_cutoffs(train_col: np.ndarray, level: float) -> Tuple[float, float]:\n",
    "    lo = np.quantile(train_col, level)\n",
    "    hi = np.quantile(train_col, 1 - level)\n",
    "    return lo, hi\n",
    "\n",
    "def apply_cutoff(x: np.ndarray, lo: float, hi: float) -> np.ndarray:\n",
    "    return np.clip(x, lo, hi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fee9cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lasso_logit', 'rf_rf'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [code]\n",
    "def make_learners(cfg: Config) -> Dict[str, Tuple[Any, Any]]:\n",
    "    learners = {}\n",
    "    if cfg.RUN_LASSO:\n",
    "        g_lasso = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"model\", LassoCV(cv=5, random_state=cfg.SEED, n_alphas=50, max_iter=5000))\n",
    "        ])\n",
    "        m_logit = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"model\", LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
    "        ])\n",
    "        learners[\"lasso_logit\"] = (g_lasso, m_logit)\n",
    "    \n",
    "    if cfg.RUN_RF:\n",
    "        g_rf = RandomForestRegressor(\n",
    "            n_estimators=cfg.RF_NEST,\n",
    "            max_depth=cfg.RF_MAXDEPTH,\n",
    "            random_state=cfg.SEED,\n",
    "            n_jobs=1,                 # IMPORTANT\n",
    "            min_samples_leaf=10\n",
    "        )\n",
    "        m_rf = RandomForestClassifier(\n",
    "            n_estimators=cfg.RF_NEST,\n",
    "            max_depth=cfg.RF_MAXDEPTH,\n",
    "            random_state=cfg.SEED,\n",
    "            n_jobs=1,                 # IMPORTANT\n",
    "            min_samples_leaf=10\n",
    "        )\n",
    "        learners[\"rf_rf\"] = (g_rf, m_rf)\n",
    "    return learners\n",
    "\n",
    "def make_huber_strategy(cfg: Config) -> Tuple[Any, Any]:\n",
    "    g_huber = Pipeline([(\"scaler\", StandardScaler()), (\"model\", HuberRegressor())])\n",
    "    m_logit = Pipeline([(\"scaler\", StandardScaler()), (\"model\", LogisticRegression(max_iter=2000, solver=\"lbfgs\"))])\n",
    "    return g_huber, m_logit\n",
    "\n",
    "LEARNERS = make_learners(CFG)\n",
    "LEARNERS.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37427f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "def crossfit_nuisance(\n",
    "    X: np.ndarray, D: np.ndarray, Y: np.ndarray,\n",
    "    g_learner, m_learner,\n",
    "    k_folds: int, seed: int\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    n = X.shape[0]\n",
    "    ghat = np.zeros(n)\n",
    "    mhat = np.zeros(n)\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=seed)\n",
    "    \n",
    "    for tr_idx, te_idx in kf.split(X):\n",
    "        X_tr, X_te = X[tr_idx], X[te_idx]\n",
    "        Y_tr, D_tr = Y[tr_idx], D[tr_idx]\n",
    "        \n",
    "        g = g_learner\n",
    "        m = m_learner\n",
    "        \n",
    "        g.fit(X_tr, Y_tr)\n",
    "        ghat[te_idx] = g.predict(X_te)\n",
    "        \n",
    "        if hasattr(m, \"predict_proba\"):\n",
    "            m.fit(X_tr, D_tr)\n",
    "            mhat[te_idx] = m.predict_proba(X_te)[:, 1]\n",
    "        else:\n",
    "            m.fit(X_tr, D_tr)\n",
    "            mhat[te_idx] = m.predict(X_te)\n",
    "    \n",
    "    return ghat, mhat\n",
    "\n",
    "def dml_theta_se_from_residuals(D_res: np.ndarray, Y_res: np.ndarray) -> Dict[str, float]:\n",
    "    n = len(D_res)\n",
    "    denom = np.mean(D_res**2)\n",
    "    theta_hat = np.mean(D_res * Y_res) / denom\n",
    "    \n",
    "    psi = (D_res * (Y_res - theta_hat * D_res)) / denom\n",
    "    se = np.sqrt(np.var(psi, ddof=1) / n)\n",
    "    \n",
    "    return {\n",
    "        \"theta_hat\": float(theta_hat),\n",
    "        \"se\": float(se),\n",
    "        \"ci_lo\": float(theta_hat - 1.96 * se),\n",
    "        \"ci_hi\": float(theta_hat + 1.96 * se),\n",
    "        \"denom_E_Dres2\": float(denom),\n",
    "    }\n",
    "\n",
    "def dml_plr_cached(D: np.ndarray, Y: np.ndarray, ghat: np.ndarray, mhat: np.ndarray, score_winsor: float) -> Dict[str, float]:\n",
    "    D_res = D - mhat\n",
    "    Y_res = Y - ghat\n",
    "    if score_winsor > 0:\n",
    "        D_res = winsorize_array(D_res, score_winsor)\n",
    "        Y_res = winsorize_array(Y_res, score_winsor)\n",
    "    return dml_theta_se_from_residuals(D_res, Y_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fee81e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gaussian',\n",
       " 'student_t_df3',\n",
       " 'student_t_df10',\n",
       " 'hetero_t_df3',\n",
       " 'contamination')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [code]\n",
    "def gen_dgp(cfg: Config, dgp_name: str, rng: np.random.Generator) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    dgp_name options:\n",
    "      - gaussian\n",
    "      - student_t_df3\n",
    "      - student_t_df10   (tail sweep)\n",
    "      - hetero_t_df3\n",
    "      - contamination\n",
    "    \"\"\"\n",
    "    N, P = cfg.N, cfg.P\n",
    "    \n",
    "    X = rng.normal(size=(N, P))\n",
    "    fX = (X[:, 0] + 0.5*X[:, 1]**2 - 0.25*np.sin(X[:, 2]))\n",
    "    \n",
    "    linp = 0.6*X[:, 0] - 0.4*X[:, 1] + 0.2*X[:, 2]\n",
    "    pscore = 1 / (1 + np.exp(-1.0 * linp))\n",
    "    D = rng.binomial(1, pscore, size=N).astype(float)\n",
    "    \n",
    "    if dgp_name == \"gaussian\":\n",
    "        U = rng.normal(size=N)\n",
    "    elif dgp_name == \"student_t_df3\":\n",
    "        U = rng.standard_t(df=cfg.STUDENT_T_DF_MAIN, size=N)\n",
    "    elif dgp_name == \"student_t_df10\":\n",
    "        U = rng.standard_t(df=cfg.STUDENT_T_DF_SWEEP, size=N)\n",
    "    elif dgp_name == \"hetero_t_df3\":\n",
    "        scale = np.exp(0.3 * X[:, 0])\n",
    "        U = scale * rng.standard_t(df=cfg.STUDENT_T_DF_MAIN, size=N)\n",
    "    elif dgp_name == \"contamination\":\n",
    "        base = rng.normal(size=N)\n",
    "        shock = rng.normal(scale=cfg.CONTAM_SCALE, size=N)\n",
    "        mask = rng.uniform(size=N) < cfg.CONTAM_EPS\n",
    "        U = np.where(mask, shock, base)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown dgp_name\")\n",
    "    \n",
    "    Y = cfg.THETA0 * D + fX + U\n",
    "    return X, D, Y\n",
    "\n",
    "DGP_LIST_MAIN = (\"gaussian\", \"student_t_df3\", \"student_t_df10\", \"hetero_t_df3\", \"contamination\")\n",
    "DGP_LIST_MAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6a087cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "def run_one_rep_dgp_main(cfg: Config, rep: int, dgp: str) -> List[Dict[str, Any]]:\n",
    "    base_seed = cfg.SEED * 100000 + rep * 10 + (abs(hash(dgp)) % 10)\n",
    "    rng = np.random.default_rng(base_seed)\n",
    "    X, D, Y = gen_dgp(cfg, dgp, rng)\n",
    "    \n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    learners = make_learners(cfg)\n",
    "    \n",
    "    for learner_key, (g, m) in learners.items():\n",
    "        ghat, mhat = crossfit_nuisance(X, D, Y, g, m, cfg.K_FOLDS, cfg.SEED)\n",
    "        \n",
    "        # baseline\n",
    "        r0 = dml_plr_cached(D, Y, ghat, mhat, score_winsor=0.0)\n",
    "        rows.append({\"rep\": rep, \"dgp\": dgp, \"learner\": learner_key, \"strategy\": \"S0_baseline\", \"winsor_level\": 0.0, **r0})\n",
    "        \n",
    "        # score-winsor sweep (cheap)\n",
    "        for w in cfg.WINSOR_LEVELS:\n",
    "            if w <= 0: \n",
    "                continue\n",
    "            r2 = dml_plr_cached(D, Y, ghat, mhat, score_winsor=float(w))\n",
    "            rows.append({\"rep\": rep, \"dgp\": dgp, \"learner\": learner_key, \"strategy\": \"S2_score_winsor\", \"winsor_level\": float(w), **r2})\n",
    "    \n",
    "    # robust nuisance once per rep/dgp\n",
    "    if cfg.RUN_ROBUST_NUISANCE:\n",
    "        g_h, m_l = make_huber_strategy(cfg)\n",
    "        ghat_h, mhat_h = crossfit_nuisance(X, D, Y, g_h, m_l, cfg.K_FOLDS, cfg.SEED)\n",
    "        r3 = dml_plr_cached(D, Y, ghat_h, mhat_h, score_winsor=0.0)\n",
    "        rows.append({\"rep\": rep, \"dgp\": dgp, \"learner\": \"huber_logit\", \"strategy\": \"S3_robust_nuisance\", \"winsor_level\": 0.0, **r3})\n",
    "    \n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30be7bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAIN tasks = 2000 = reps(400) × dgp(5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=-1)]: Done 320 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=-1)]: Done 408 tasks      | elapsed: 42.1min\n",
      "[Parallel(n_jobs=-1)]: Done 512 tasks      | elapsed: 61.7min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed: 73.9min\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed: 86.2min\n",
      "[Parallel(n_jobs=-1)]: Done 856 tasks      | elapsed: 154.4min\n",
      "[Parallel(n_jobs=-1)]: Done 992 tasks      | elapsed: 175.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed: 186.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1280 tasks      | elapsed: 207.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1432 tasks      | elapsed: 220.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1600 tasks      | elapsed: 242.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1768 tasks      | elapsed: 263.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1924 tasks      | elapsed: 282.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1961 tasks      | elapsed: 286.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed: 294.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAIN MC finished in sec: 17660.1\n",
      "              dgp      learner            strategy  winsor_level  mean_theta  \\\n",
      "0   contamination  huber_logit  S3_robust_nuisance         0.000    0.489860   \n",
      "1   contamination  lasso_logit         S0_baseline         0.000    0.461554   \n",
      "2   contamination  lasso_logit     S2_score_winsor         0.005    0.463072   \n",
      "3   contamination  lasso_logit     S2_score_winsor         0.010    0.459847   \n",
      "4   contamination  lasso_logit     S2_score_winsor         0.025    0.457467   \n",
      "5   contamination  lasso_logit     S2_score_winsor         0.050    0.450329   \n",
      "6   contamination        rf_rf         S0_baseline         0.000    0.451139   \n",
      "7   contamination        rf_rf     S2_score_winsor         0.005    0.452198   \n",
      "8   contamination        rf_rf     S2_score_winsor         0.010    0.446843   \n",
      "9   contamination        rf_rf     S2_score_winsor         0.025    0.436875   \n",
      "10  contamination        rf_rf     S2_score_winsor         0.050    0.418586   \n",
      "11       gaussian  huber_logit  S3_robust_nuisance         0.000    0.501190   \n",
      "\n",
      "        bias      rmse   mean_se  mean_width  n_reps  coverage    cov_se  \\\n",
      "0  -0.010140  0.384008  0.366194    1.435480     400    0.9525  0.010635   \n",
      "1  -0.038446  0.388060  0.367246    1.439606     400    0.9450  0.011399   \n",
      "2  -0.036928  0.329988  0.307909    1.207003     400    0.9450  0.011399   \n",
      "3  -0.040153  0.265713  0.244682    0.959152     400    0.9350  0.012326   \n",
      "4  -0.042533  0.119137  0.107269    0.420493     400    0.9300  0.012757   \n",
      "5  -0.049671  0.098211  0.088574    0.347211     400    0.9200  0.013565   \n",
      "6  -0.048861  0.382659  0.373363    1.463582     400    0.9525  0.010635   \n",
      "7  -0.047802  0.326343  0.312236    1.223966     400    0.9450  0.011399   \n",
      "8  -0.053157  0.266155  0.248899    0.975684     400    0.9450  0.011399   \n",
      "9  -0.063125  0.137957  0.114875    0.450309     400    0.8950  0.015328   \n",
      "10 -0.081414  0.128746  0.093822    0.367784     400    0.8575  0.017478   \n",
      "11  0.001190  0.089003  0.080889    0.317084     400    0.9025  0.014832   \n",
      "\n",
      "    cov_ci_lo  cov_ci_hi  \n",
      "0    0.931655   0.973345  \n",
      "1    0.922658   0.967342  \n",
      "2    0.922658   0.967342  \n",
      "3    0.910840   0.959160  \n",
      "4    0.904996   0.955004  \n",
      "5    0.893413   0.946587  \n",
      "6    0.931655   0.973345  \n",
      "7    0.922658   0.967342  \n",
      "8    0.922658   0.967342  \n",
      "9    0.864958   0.925042  \n",
      "10   0.823243   0.891757  \n",
      "11   0.873430   0.931570  \n",
      "Saved: c:\\Users\\starw\\.vscode\\practice\\gapA_outputs_v3\\main_mc_raw.csv\n",
      "Saved: c:\\Users\\starw\\.vscode\\practice\\gapA_outputs_v3\\main_mc_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "def summarize_mc_with_cov_ci(df: pd.DataFrame, theta0: float) -> pd.DataFrame:\n",
    "    g = df.groupby([\"dgp\", \"learner\", \"strategy\", \"winsor_level\"], as_index=False)\n",
    "    \n",
    "    out = g.agg(\n",
    "        mean_theta=(\"theta_hat\", \"mean\"),\n",
    "        bias=(\"theta_hat\", lambda x: float(np.mean(x - theta0))),\n",
    "        rmse=(\"theta_hat\", lambda x: float(np.sqrt(np.mean((x - theta0)**2)))),\n",
    "        mean_se=(\"se\", \"mean\"),\n",
    "        mean_width=(\"ci_hi\", lambda hi: float(np.mean(hi - df.loc[hi.index, \"ci_lo\"]))),\n",
    "        n_reps=(\"theta_hat\", \"count\"),\n",
    "        cov_rate=(\"theta_hat\", lambda x: float(np.mean(\n",
    "            (df.loc[x.index, \"ci_lo\"] <= theta0) & (theta0 <= df.loc[x.index, \"ci_hi\"])\n",
    "        )))\n",
    "    )\n",
    "    # Binomial SE and CI for coverage\n",
    "    p = out[\"cov_rate\"].to_numpy()\n",
    "    n = out[\"n_reps\"].to_numpy()\n",
    "    cov_se = np.sqrt(np.maximum(p * (1 - p) / n, 0))\n",
    "    out[\"cov_se\"] = cov_se\n",
    "    out[\"cov_ci_lo\"] = np.clip(p - 1.96 * cov_se, 0, 1)\n",
    "    out[\"cov_ci_hi\"] = np.clip(p + 1.96 * cov_se, 0, 1)\n",
    "    out = out.rename(columns={\"cov_rate\": \"coverage\"})\n",
    "    return out\n",
    "\n",
    "RAW_MAIN, SUM_MAIN = None, None\n",
    "\n",
    "if CFG.RUN_MAIN_MC:\n",
    "    t0 = time.time()\n",
    "    tasks = [(rep, dgp) for rep in range(CFG.MAIN_REPS) for dgp in DGP_LIST_MAIN]\n",
    "    print(f\"MAIN tasks = {len(tasks)} = reps({CFG.MAIN_REPS}) × dgp({len(DGP_LIST_MAIN)})\")\n",
    "    \n",
    "    blocks = Parallel(n_jobs=CFG.N_JOBS, verbose=10, batch_size=CFG.BATCH_SIZE)(\n",
    "        delayed(run_one_rep_dgp_main)(CFG, rep, dgp) for (rep, dgp) in tasks\n",
    "    )\n",
    "    flat = [r for blk in blocks for r in blk]\n",
    "    RAW_MAIN = pd.DataFrame(flat)\n",
    "    SUM_MAIN = summarize_mc_with_cov_ci(RAW_MAIN, CFG.THETA0)\n",
    "    \n",
    "    print(\"MAIN MC finished in sec:\", round(time.time() - t0, 1))\n",
    "    print(SUM_MAIN.sort_values([\"dgp\",\"learner\",\"strategy\",\"winsor_level\"]).head(12))\n",
    "    \n",
    "    if CFG.SAVE_TABLES:\n",
    "        RAW_MAIN.to_csv(os.path.join(OUTDIR, \"main_mc_raw.csv\"), index=False)\n",
    "        SUM_MAIN.to_csv(os.path.join(OUTDIR, \"main_mc_summary.csv\"), index=False)\n",
    "        print(\"Saved:\", os.path.abspath(os.path.join(OUTDIR, \"main_mc_raw.csv\")))\n",
    "        print(\"Saved:\", os.path.abspath(os.path.join(OUTDIR, \"main_mc_summary.csv\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1709c755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPX(expensive) tasks = 400 = reps(200) × dgp(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed: 72.4min\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed: 73.5min\n",
      "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed: 117.1min\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed: 156.7min\n",
      "[Parallel(n_jobs=-1)]: Done 313 tasks      | elapsed: 160.3min\n",
      "[Parallel(n_jobs=-1)]: Done 324 tasks      | elapsed: 163.9min\n",
      "[Parallel(n_jobs=-1)]: Done 337 tasks      | elapsed: 168.8min\n",
      "[Parallel(n_jobs=-1)]: Done 350 tasks      | elapsed: 173.2min\n",
      "[Parallel(n_jobs=-1)]: Done 365 tasks      | elapsed: 178.4min\n",
      "[Parallel(n_jobs=-1)]: Done 380 tasks      | elapsed: 183.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPX finished in sec: 12359.3\n",
      "              dgp      learner          strategy  winsor_level  mean_theta  \\\n",
      "0   contamination  lasso_logit    S1_data_winsor          0.01    0.468732   \n",
      "1   contamination  lasso_logit    S1_data_winsor          0.05    0.434932   \n",
      "2   contamination  lasso_logit  S4_honest_winsor          0.01    0.486729   \n",
      "3   contamination  lasso_logit  S4_honest_winsor          0.05    0.496800   \n",
      "4   contamination        rf_rf    S1_data_winsor          0.01    0.461549   \n",
      "5   contamination        rf_rf    S1_data_winsor          0.05    0.441490   \n",
      "6   contamination        rf_rf  S4_honest_winsor          0.01    0.482576   \n",
      "7   contamination        rf_rf  S4_honest_winsor          0.05    0.532026   \n",
      "8   student_t_df3  lasso_logit    S1_data_winsor          0.01    0.459919   \n",
      "9   student_t_df3  lasso_logit    S1_data_winsor          0.05    0.435490   \n",
      "10  student_t_df3  lasso_logit  S4_honest_winsor          0.01    0.468579   \n",
      "11  student_t_df3  lasso_logit  S4_honest_winsor          0.05    0.478733   \n",
      "\n",
      "        bias      rmse   mean_se  mean_width  n_reps  coverage    cov_se  \\\n",
      "0  -0.031268  0.255493  0.242291    0.949780     200     0.930  0.018042   \n",
      "1  -0.065068  0.113187  0.086080    0.337432     200     0.855  0.024897   \n",
      "2  -0.013271  0.365001  0.368478    1.444433     200     0.965  0.012995   \n",
      "3  -0.003200  0.360381  0.366577    1.436982     200     0.965  0.012995   \n",
      "4  -0.038451  0.254476  0.244482    0.958370     200     0.935  0.017432   \n",
      "5  -0.058510  0.102456  0.081940    0.321206     200     0.895  0.021677   \n",
      "6  -0.017424  0.365585  0.371297    1.455483     200     0.965  0.012995   \n",
      "7   0.032026  0.360765  0.369207    1.447290     200     0.970  0.012062   \n",
      "8  -0.040081  0.112140  0.105792    0.414703     200     0.930  0.018042   \n",
      "9  -0.064510  0.112847  0.092532    0.362725     200     0.890  0.022125   \n",
      "10 -0.031421  0.122387  0.121396    0.475874     200     0.950  0.015411   \n",
      "11 -0.021267  0.120145  0.121783    0.477391     200     0.945  0.016121   \n",
      "\n",
      "    cov_ci_lo  cov_ci_hi  \n",
      "0    0.894638   0.965362  \n",
      "1    0.806201   0.903799  \n",
      "2    0.939529   0.990471  \n",
      "3    0.939529   0.990471  \n",
      "4    0.900833   0.969167  \n",
      "5    0.852514   0.937486  \n",
      "6    0.939529   0.990471  \n",
      "7    0.946358   0.993642  \n",
      "8    0.894638   0.965362  \n",
      "9    0.846636   0.933364  \n",
      "10   0.919794   0.980206  \n",
      "11   0.913404   0.976596  \n",
      "Saved: c:\\Users\\starw\\.vscode\\practice\\gapA_outputs_v3\\appx_expensive_raw.csv\n",
      "Saved: c:\\Users\\starw\\.vscode\\practice\\gapA_outputs_v3\\appx_expensive_summary.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed: 206.0min finished\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "def dml_plr_honest_foldwise(\n",
    "    X: np.ndarray, D: np.ndarray, Y: np.ndarray,\n",
    "    g_learner, m_learner,\n",
    "    k_folds: int, seed: int,\n",
    "    winsor_level: float\n",
    ") -> Dict[str, float]:\n",
    "    n, p = X.shape\n",
    "    ghat = np.zeros(n)\n",
    "    mhat = np.zeros(n)\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=seed)\n",
    "    \n",
    "    for tr_idx, te_idx in kf.split(X):\n",
    "        X_tr, X_te = X[tr_idx].copy(), X[te_idx].copy()\n",
    "        Y_tr, D_tr = Y[tr_idx].copy(), D[tr_idx].copy()\n",
    "        \n",
    "        if winsor_level > 0:\n",
    "            # X cutoffs from TRAIN only\n",
    "            for j in range(p):\n",
    "                lo, hi = foldwise_cutoffs(X_tr[:, j], winsor_level)\n",
    "                X_tr[:, j] = apply_cutoff(X_tr[:, j], lo, hi)\n",
    "                X_te[:, j] = apply_cutoff(X_te[:, j], lo, hi)\n",
    "            # Y cutoffs from TRAIN only\n",
    "            loY, hiY = foldwise_cutoffs(Y_tr, winsor_level)\n",
    "            Y_tr = apply_cutoff(Y_tr, loY, hiY)\n",
    "        \n",
    "        g = g_learner\n",
    "        m = m_learner\n",
    "        \n",
    "        g.fit(X_tr, Y_tr)\n",
    "        ghat[te_idx] = g.predict(X_te)\n",
    "        \n",
    "        if hasattr(m, \"predict_proba\"):\n",
    "            m.fit(X_tr, D_tr)\n",
    "            mhat[te_idx] = m.predict_proba(X_te)[:, 1]\n",
    "        else:\n",
    "            m.fit(X_tr, D_tr)\n",
    "            mhat[te_idx] = m.predict(X_te)\n",
    "    \n",
    "    return dml_plr_cached(D, Y, ghat, mhat, score_winsor=0.0)\n",
    "\n",
    "def run_one_rep_dgp_expensive(cfg: Config, rep: int, dgp: str) -> List[Dict[str, Any]]:\n",
    "    base_seed = cfg.SEED * 200000 + rep * 10 + (abs(hash(dgp)) % 10)\n",
    "    rng = np.random.default_rng(base_seed)\n",
    "    X, D, Y = gen_dgp(cfg, dgp, rng)\n",
    "    \n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    learners = make_learners(cfg)\n",
    "    \n",
    "    for learner_key, (g, m) in learners.items():\n",
    "        if learner_key not in cfg.EXPENSIVE_LEARNERS:\n",
    "            continue\n",
    "        \n",
    "        for w in cfg.EXPENSIVE_WINSOR_LEVELS:\n",
    "            # S1: data-winsor (refit nuisance)\n",
    "            Xw = winsorize_matrix_by_col(X, w)\n",
    "            Yw = winsorize_array(Y, w)\n",
    "            ghat_w, mhat_w = crossfit_nuisance(Xw, D, Yw, g, m, cfg.K_FOLDS, cfg.SEED)\n",
    "            r1 = dml_plr_cached(D, Yw, ghat_w, mhat_w, score_winsor=0.0)\n",
    "            rows.append({\"rep\": rep, \"dgp\": dgp, \"learner\": learner_key, \"strategy\": \"S1_data_winsor\", \"winsor_level\": float(w), **r1})\n",
    "            \n",
    "            # S4: honest winsor (refit nuisance within fold with train cutoffs)\n",
    "            r4 = dml_plr_honest_foldwise(X, D, Y, g, m, cfg.K_FOLDS, cfg.SEED, float(w))\n",
    "            rows.append({\"rep\": rep, \"dgp\": dgp, \"learner\": learner_key, \"strategy\": \"S4_honest_winsor\", \"winsor_level\": float(w), **r4})\n",
    "    \n",
    "    return rows\n",
    "\n",
    "RAW_APPX, SUM_APPX = None, None\n",
    "\n",
    "if CFG.RUN_APPX_EXPENSIVE:\n",
    "    t0 = time.time()\n",
    "    tasks = [(rep, dgp) for rep in range(CFG.APPX_REPS) for dgp in CFG.EXPENSIVE_DGPS]\n",
    "    print(f\"APPX(expensive) tasks = {len(tasks)} = reps({CFG.APPX_REPS}) × dgp({len(CFG.EXPENSIVE_DGPS)})\")\n",
    "    \n",
    "    blocks = Parallel(n_jobs=CFG.N_JOBS, verbose=10, batch_size=max(1, CFG.BATCH_SIZE))(\n",
    "        delayed(run_one_rep_dgp_expensive)(CFG, rep, dgp) for (rep, dgp) in tasks\n",
    "    )\n",
    "    flat = [r for blk in blocks for r in blk]\n",
    "    RAW_APPX = pd.DataFrame(flat)\n",
    "    SUM_APPX = summarize_mc_with_cov_ci(RAW_APPX, CFG.THETA0)\n",
    "    \n",
    "    print(\"APPX finished in sec:\", round(time.time() - t0, 1))\n",
    "    print(SUM_APPX.sort_values([\"dgp\",\"learner\",\"strategy\",\"winsor_level\"]).head(12))\n",
    "    \n",
    "    if CFG.SAVE_TABLES:\n",
    "        RAW_APPX.to_csv(os.path.join(OUTDIR, \"appx_expensive_raw.csv\"), index=False)\n",
    "        SUM_APPX.to_csv(os.path.join(OUTDIR, \"appx_expensive_summary.csv\"), index=False)\n",
    "        print(\"Saved:\", os.path.abspath(os.path.join(OUTDIR, \"appx_expensive_raw.csv\")))\n",
    "        print(\"Saved:\", os.path.abspath(os.path.join(OUTDIR, \"appx_expensive_summary.csv\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c56a5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figures under: c:\\Users\\starw\\.vscode\\practice\\gapA_outputs_v3\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "def plot_metric_vs_winsor(sum_df: pd.DataFrame, metric: str, out_prefix: str):\n",
    "    \"\"\"\n",
    "    metric: \"coverage\", \"mean_width\", \"rmse\", \"bias\"\n",
    "    \"\"\"\n",
    "    for dgp in sorted(sum_df[\"dgp\"].unique()):\n",
    "        sub = sum_df[sum_df[\"dgp\"] == dgp].copy()\n",
    "        for learner in sorted(sub[\"learner\"].unique()):\n",
    "            sub2 = sub[sub[\"learner\"] == learner].copy()\n",
    "            \n",
    "            plt.figure(figsize=(9,5))\n",
    "            for strat in sorted(sub2[\"strategy\"].unique()):\n",
    "                s3 = sub2[sub2[\"strategy\"] == strat].sort_values(\"winsor_level\")\n",
    "                plt.plot(s3[\"winsor_level\"], s3[metric], marker=\"o\", label=strat)\n",
    "            if metric == \"coverage\":\n",
    "                plt.axhline(0.95, linestyle=\"--\")\n",
    "            plt.title(f\"{metric} vs winsor_level | dgp={dgp} | learner={learner}\")\n",
    "            plt.xlabel(\"winsor_level\")\n",
    "            plt.ylabel(metric)\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            if CFG.SAVE_FIGS:\n",
    "                path = os.path.join(OUTDIR, f\"{out_prefix}_{metric}_{dgp}_{learner}.png\")\n",
    "                plt.savefig(path, dpi=200)\n",
    "                plt.close()\n",
    "            else:\n",
    "                plt.show()\n",
    "\n",
    "if (SUM_MAIN is not None) and CFG.SAVE_FIGS:\n",
    "    plot_metric_vs_winsor(SUM_MAIN, \"coverage\", \"fig_main\")\n",
    "    plot_metric_vs_winsor(SUM_MAIN, \"mean_width\", \"fig_main\")\n",
    "    plot_metric_vs_winsor(SUM_MAIN, \"rmse\", \"fig_main\")\n",
    "    print(\"Saved figures under:\", os.path.abspath(OUTDIR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29d3bbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"timestamp\": \"2026-01-06 19:29:25\",\n",
      "  \"config\": {\n",
      "    \"RUN_MAIN_MC\": true,\n",
      "    \"MAIN_REPS\": 400,\n",
      "    \"N\": 1000,\n",
      "    \"P\": 50,\n",
      "    \"THETA0\": 0.5,\n",
      "    \"K_FOLDS\": 5,\n",
      "    \"SEED\": 42,\n",
      "    \"WINSOR_LEVELS\": [\n",
      "      0.0,\n",
      "      0.005,\n",
      "      0.01,\n",
      "      0.025,\n",
      "      0.05\n",
      "    ],\n",
      "    \"RUN_LASSO\": true,\n",
      "    \"RUN_RF\": true,\n",
      "    \"RF_NEST\": 300,\n",
      "    \"RF_MAXDEPTH\": 8,\n",
      "    \"RUN_ROBUST_NUISANCE\": true,\n",
      "    \"STUDENT_T_DF_MAIN\": 3,\n",
      "    \"STUDENT_T_DF_SWEEP\": 10,\n",
      "    \"CONTAM_EPS\": 0.05,\n",
      "    \"CONTAM_SCALE\": 25.0,\n",
      "    \"RUN_APPX_EXPENSIVE\": true,\n",
      "    \"APPX_REPS\": 200,\n",
      "    \"EXPENSIVE_WINSOR_LEVELS\": [\n",
      "      0.01,\n",
      "      0.05\n",
      "    ],\n",
      "    \"EXPENSIVE_DGPS\": [\n",
      "      \"contamination\",\n",
      "      \"student_t_df3\"\n",
      "    ],\n",
      "    \"EXPENSIVE_LEARNERS\": [\n",
      "      \"lasso_logit\",\n",
      "      \"rf_rf\"\n",
      "    ],\n",
      "    \"N_JOBS\": -1,\n",
      "    \"BATCH_SIZE\": 8,\n",
      "    \"SAVE_TABLES\": true,\n",
      "    \"SAVE_FIGS\": true\n",
      "  },\n",
      "  \"outdir\": \"c:\\\\Users\\\\starw\\\\.vscode\\\\practice\\\\gapA_outputs_v3\",\n",
      "  \"files\": {\n",
      "    \"main_mc_raw\": \"c:\\\\Users\\\\starw\\\\.vscode\\\\practice\\\\gapA_outputs_v3\\\\main_mc_raw.csv\",\n",
      "    \"main_mc_summary\": \"c:\\\\Users\\\\starw\\\\.vscode\\\\practice\\\\gapA_outputs_v3\\\\main_mc_summary.csv\",\n",
      "    \"appx_expensive_raw\": \"c:\\\\Users\\\\starw\\\\.vscode\\\\practice\\\\gapA_outputs_v3\\\\appx_expensive_raw.csv\",\n",
      "    \"appx_expensive_summary\": \"c:\\\\Users\\\\starw\\\\.vscode\\\\practice\\\\gapA_outputs_v3\\\\appx_expensive_summary.csv\"\n",
      "  },\n",
      "  \"main_head\": [\n",
      "    {\n",
      "      \"dgp\": \"contamination\",\n",
      "      \"learner\": \"huber_logit\",\n",
      "      \"strategy\": \"S3_robust_nuisance\",\n",
      "      \"winsor_level\": 0.0,\n",
      "      \"mean_theta\": 0.48986037475131616,\n",
      "      \"bias\": -0.010139625248683832,\n",
      "      \"rmse\": 0.38400802335927403,\n",
      "      \"mean_se\": 0.36619391947012353,\n",
      "      \"mean_width\": 1.4354801643228843,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.9525,\n",
      "      \"cov_se\": 0.010635289135702893,\n",
      "      \"cov_ci_lo\": 0.9316548332940223,\n",
      "      \"cov_ci_hi\": 0.9733451667059777\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"contamination\",\n",
      "      \"learner\": \"lasso_logit\",\n",
      "      \"strategy\": \"S0_baseline\",\n",
      "      \"winsor_level\": 0.0,\n",
      "      \"mean_theta\": 0.46155439183152497,\n",
      "      \"bias\": -0.03844560816847504,\n",
      "      \"rmse\": 0.3880603626470345,\n",
      "      \"mean_se\": 0.3672463024250592,\n",
      "      \"mean_width\": 1.4396055055062322,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.945,\n",
      "      \"cov_se\": 0.011399013115178002,\n",
      "      \"cov_ci_lo\": 0.922657934294251,\n",
      "      \"cov_ci_hi\": 0.9673420657057489\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"contamination\",\n",
      "      \"learner\": \"lasso_logit\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.005,\n",
      "      \"mean_theta\": 0.4630719656153377,\n",
      "      \"bias\": -0.036928034384662294,\n",
      "      \"rmse\": 0.3299882491631265,\n",
      "      \"mean_se\": 0.30790881348152654,\n",
      "      \"mean_width\": 1.207002548847584,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.945,\n",
      "      \"cov_se\": 0.011399013115178002,\n",
      "      \"cov_ci_lo\": 0.922657934294251,\n",
      "      \"cov_ci_hi\": 0.9673420657057489\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"contamination\",\n",
      "      \"learner\": \"lasso_logit\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.01,\n",
      "      \"mean_theta\": 0.4598466475453036,\n",
      "      \"bias\": -0.0401533524546964,\n",
      "      \"rmse\": 0.2657132491721491,\n",
      "      \"mean_se\": 0.24468166474527586,\n",
      "      \"mean_width\": 0.9591521258014813,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.935,\n",
      "      \"cov_se\": 0.012326293035621046,\n",
      "      \"cov_ci_lo\": 0.9108404656501828,\n",
      "      \"cov_ci_hi\": 0.9591595343498173\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"contamination\",\n",
      "      \"learner\": \"lasso_logit\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.025,\n",
      "      \"mean_theta\": 0.4574670045024789,\n",
      "      \"bias\": -0.04253299549752109,\n",
      "      \"rmse\": 0.1191370254451999,\n",
      "      \"mean_se\": 0.10726863743868253,\n",
      "      \"mean_width\": 0.42049305875963555,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.93,\n",
      "      \"cov_se\": 0.01275735082217307,\n",
      "      \"cov_ci_lo\": 0.9049955923885409,\n",
      "      \"cov_ci_hi\": 0.9550044076114592\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"contamination\",\n",
      "      \"learner\": \"lasso_logit\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.05,\n",
      "      \"mean_theta\": 0.4503290217309448,\n",
      "      \"bias\": -0.04967097826905523,\n",
      "      \"rmse\": 0.09821128778288567,\n",
      "      \"mean_se\": 0.08857424381103303,\n",
      "      \"mean_width\": 0.3472110357392495,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.92,\n",
      "      \"cov_se\": 0.013564659966250532,\n",
      "      \"cov_ci_lo\": 0.893413266466149,\n",
      "      \"cov_ci_hi\": 0.946586733533851\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"contamination\",\n",
      "      \"learner\": \"rf_rf\",\n",
      "      \"strategy\": \"S0_baseline\",\n",
      "      \"winsor_level\": 0.0,\n",
      "      \"mean_theta\": 0.45113856858552365,\n",
      "      \"bias\": -0.04886143141447637,\n",
      "      \"rmse\": 0.3826594235103707,\n",
      "      \"mean_se\": 0.37336284677630316,\n",
      "      \"mean_width\": 1.463582359363108,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.9525,\n",
      "      \"cov_se\": 0.010635289135702893,\n",
      "      \"cov_ci_lo\": 0.9316548332940223,\n",
      "      \"cov_ci_hi\": 0.9733451667059777\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"contamination\",\n",
      "      \"learner\": \"rf_rf\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.005,\n",
      "      \"mean_theta\": 0.4521982296972713,\n",
      "      \"bias\": -0.0478017703027287,\n",
      "      \"rmse\": 0.3263428808905192,\n",
      "      \"mean_se\": 0.3122362644624225,\n",
      "      \"mean_width\": 1.223966156692696,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.945,\n",
      "      \"cov_se\": 0.011399013115178002,\n",
      "      \"cov_ci_lo\": 0.922657934294251,\n",
      "      \"cov_ci_hi\": 0.9673420657057489\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"contamination\",\n",
      "      \"learner\": \"rf_rf\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.01,\n",
      "      \"mean_theta\": 0.44684272270333,\n",
      "      \"bias\": -0.053157277296670025,\n",
      "      \"rmse\": 0.26615488114800423,\n",
      "      \"mean_se\": 0.24889910197641832,\n",
      "      \"mean_width\": 0.9756844797475597,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.945,\n",
      "      \"cov_se\": 0.011399013115178002,\n",
      "      \"cov_ci_lo\": 0.922657934294251,\n",
      "      \"cov_ci_hi\": 0.9673420657057489\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"contamination\",\n",
      "      \"learner\": \"rf_rf\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.025,\n",
      "      \"mean_theta\": 0.4368746504221043,\n",
      "      \"bias\": -0.06312534957789566,\n",
      "      \"rmse\": 0.13795698424253408,\n",
      "      \"mean_se\": 0.11487485392278611,\n",
      "      \"mean_width\": 0.4503094273773216,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.895,\n",
      "      \"cov_se\": 0.015327671055969331,\n",
      "      \"cov_ci_lo\": 0.8649577647303002,\n",
      "      \"cov_ci_hi\": 0.9250422352696999\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"contamination\",\n",
      "      \"learner\": \"rf_rf\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.05,\n",
      "      \"mean_theta\": 0.41858562039275266,\n",
      "      \"bias\": -0.08141437960724733,\n",
      "      \"rmse\": 0.1287460138054467,\n",
      "      \"mean_se\": 0.0938224975829686,\n",
      "      \"mean_width\": 0.36778419052523686,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.8575,\n",
      "      \"cov_se\": 0.017478111311008404,\n",
      "      \"cov_ci_lo\": 0.8232429018304236,\n",
      "      \"cov_ci_hi\": 0.8917570981695765\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"gaussian\",\n",
      "      \"learner\": \"huber_logit\",\n",
      "      \"strategy\": \"S3_robust_nuisance\",\n",
      "      \"winsor_level\": 0.0,\n",
      "      \"mean_theta\": 0.5011898519991691,\n",
      "      \"bias\": 0.0011898519991690832,\n",
      "      \"rmse\": 0.08900307510807702,\n",
      "      \"mean_se\": 0.08088877085742928,\n",
      "      \"mean_width\": 0.31708398176112274,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.9025,\n",
      "      \"cov_se\": 0.014831870246196198,\n",
      "      \"cov_ci_lo\": 0.8734295343174554,\n",
      "      \"cov_ci_hi\": 0.9315704656825445\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"gaussian\",\n",
      "      \"learner\": \"lasso_logit\",\n",
      "      \"strategy\": \"S0_baseline\",\n",
      "      \"winsor_level\": 0.0,\n",
      "      \"mean_theta\": 0.47456716674474725,\n",
      "      \"bias\": -0.02543283325525276,\n",
      "      \"rmse\": 0.0857571161426918,\n",
      "      \"mean_se\": 0.07880877531327345,\n",
      "      \"mean_width\": 0.3089303992280319,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.92,\n",
      "      \"cov_se\": 0.013564659966250532,\n",
      "      \"cov_ci_lo\": 0.893413266466149,\n",
      "      \"cov_ci_hi\": 0.946586733533851\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"gaussian\",\n",
      "      \"learner\": \"lasso_logit\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.005,\n",
      "      \"mean_theta\": 0.47140525955803314,\n",
      "      \"bias\": -0.02859474044196685,\n",
      "      \"rmse\": 0.08590362088903518,\n",
      "      \"mean_se\": 0.0776562334695916,\n",
      "      \"mean_width\": 0.3044124352007991,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.9125,\n",
      "      \"cov_se\": 0.014128318194321646,\n",
      "      \"cov_ci_lo\": 0.8848084963391295,\n",
      "      \"cov_ci_hi\": 0.9401915036608705\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"gaussian\",\n",
      "      \"learner\": \"lasso_logit\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.01,\n",
      "      \"mean_theta\": 0.4682037583543519,\n",
      "      \"bias\": -0.031796241645648045,\n",
      "      \"rmse\": 0.08612094844451676,\n",
      "      \"mean_se\": 0.07672227590756847,\n",
      "      \"mean_width\": 0.3007513215576684,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.915,\n",
      "      \"cov_se\": 0.013944084767384337,\n",
      "      \"cov_ci_lo\": 0.8876695938559267,\n",
      "      \"cov_ci_hi\": 0.9423304061440734\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"gaussian\",\n",
      "      \"learner\": \"lasso_logit\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.025,\n",
      "      \"mean_theta\": 0.45946270956420276,\n",
      "      \"bias\": -0.0405372904357972,\n",
      "      \"rmse\": 0.08809648474476207,\n",
      "      \"mean_se\": 0.07456579817544698,\n",
      "      \"mean_width\": 0.29229792884775213,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.9,\n",
      "      \"cov_se\": 0.015,\n",
      "      \"cov_ci_lo\": 0.8706,\n",
      "      \"cov_ci_hi\": 0.9294\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"gaussian\",\n",
      "      \"learner\": \"lasso_logit\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.05,\n",
      "      \"mean_theta\": 0.44518183817628276,\n",
      "      \"bias\": -0.05481816182371722,\n",
      "      \"rmse\": 0.09343970384340299,\n",
      "      \"mean_se\": 0.07161053466263897,\n",
      "      \"mean_width\": 0.2807132958775448,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.8575,\n",
      "      \"cov_se\": 0.017478111311008404,\n",
      "      \"cov_ci_lo\": 0.8232429018304236,\n",
      "      \"cov_ci_hi\": 0.8917570981695765\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"gaussian\",\n",
      "      \"learner\": \"rf_rf\",\n",
      "      \"strategy\": \"S0_baseline\",\n",
      "      \"winsor_level\": 0.0,\n",
      "      \"mean_theta\": 0.48660652165365437,\n",
      "      \"bias\": -0.013393478346345656,\n",
      "      \"rmse\": 0.07437326814328234,\n",
      "      \"mean_se\": 0.07257188965555088,\n",
      "      \"mean_width\": 0.2844818074497594,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.94,\n",
      "      \"cov_se\": 0.011874342087037922,\n",
      "      \"cov_ci_lo\": 0.9167262895094056,\n",
      "      \"cov_ci_hi\": 0.9632737104905943\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"gaussian\",\n",
      "      \"learner\": \"rf_rf\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.005,\n",
      "      \"mean_theta\": 0.48279994980281493,\n",
      "      \"bias\": -0.017200050197185096,\n",
      "      \"rmse\": 0.07424135986310944,\n",
      "      \"mean_se\": 0.07136026205457811,\n",
      "      \"mean_width\": 0.27973222725394625,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.9325,\n",
      "      \"cov_se\": 0.0125442965127583,\n",
      "      \"cov_ci_lo\": 0.9079131788349937,\n",
      "      \"cov_ci_hi\": 0.9570868211650063\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"gaussian\",\n",
      "      \"learner\": \"rf_rf\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.01,\n",
      "      \"mean_theta\": 0.47861225212384106,\n",
      "      \"bias\": -0.021387747876158915,\n",
      "      \"rmse\": 0.07469795145800998,\n",
      "      \"mean_se\": 0.07052814411271574,\n",
      "      \"mean_width\": 0.2764703249218457,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.9275,\n",
      "      \"cov_se\": 0.012965699942540704,\n",
      "      \"cov_ci_lo\": 0.9020872281126202,\n",
      "      \"cov_ci_hi\": 0.9529127718873798\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"gaussian\",\n",
      "      \"learner\": \"rf_rf\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.025,\n",
      "      \"mean_theta\": 0.46571200040624533,\n",
      "      \"bias\": -0.03428799959375469,\n",
      "      \"rmse\": 0.07765047074973287,\n",
      "      \"mean_se\": 0.06846090322153872,\n",
      "      \"mean_width\": 0.26836674062843174,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.9025,\n",
      "      \"cov_se\": 0.014831870246196198,\n",
      "      \"cov_ci_lo\": 0.8734295343174554,\n",
      "      \"cov_ci_hi\": 0.9315704656825445\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"gaussian\",\n",
      "      \"learner\": \"rf_rf\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.05,\n",
      "      \"mean_theta\": 0.44418721527716715,\n",
      "      \"bias\": -0.055812784722832874,\n",
      "      \"rmse\": 0.08684327658810326,\n",
      "      \"mean_se\": 0.06544693768668934,\n",
      "      \"mean_width\": 0.25655199573182225,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.87,\n",
      "      \"cov_se\": 0.016815171720800236,\n",
      "      \"cov_ci_lo\": 0.8370422634272315,\n",
      "      \"cov_ci_hi\": 0.9029577365727685\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"hetero_t_df3\",\n",
      "      \"learner\": \"huber_logit\",\n",
      "      \"strategy\": \"S3_robust_nuisance\",\n",
      "      \"winsor_level\": 0.0,\n",
      "      \"mean_theta\": 0.49341667466027284,\n",
      "      \"bias\": -0.006583325339727203,\n",
      "      \"rmse\": 0.14152749868773454,\n",
      "      \"mean_se\": 0.1297370659247589,\n",
      "      \"mean_width\": 0.5085692984250549,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.94,\n",
      "      \"cov_se\": 0.011874342087037922,\n",
      "      \"cov_ci_lo\": 0.9167262895094056,\n",
      "      \"cov_ci_hi\": 0.9632737104905943\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"hetero_t_df3\",\n",
      "      \"learner\": \"lasso_logit\",\n",
      "      \"strategy\": \"S0_baseline\",\n",
      "      \"winsor_level\": 0.0,\n",
      "      \"mean_theta\": 0.46577678433014374,\n",
      "      \"bias\": -0.034223215669856234,\n",
      "      \"rmse\": 0.1395061957828268,\n",
      "      \"mean_se\": 0.1280819858426671,\n",
      "      \"mean_width\": 0.502081384503255,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.94,\n",
      "      \"cov_se\": 0.011874342087037922,\n",
      "      \"cov_ci_lo\": 0.9167262895094056,\n",
      "      \"cov_ci_hi\": 0.9632737104905943\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"hetero_t_df3\",\n",
      "      \"learner\": \"lasso_logit\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.005,\n",
      "      \"mean_theta\": 0.46260703697122113,\n",
      "      \"bias\": -0.037392963028778856,\n",
      "      \"rmse\": 0.1258094949412685,\n",
      "      \"mean_se\": 0.1148471514580677,\n",
      "      \"mean_width\": 0.4502008337156254,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.9325,\n",
      "      \"cov_se\": 0.0125442965127583,\n",
      "      \"cov_ci_lo\": 0.9079131788349937,\n",
      "      \"cov_ci_hi\": 0.9570868211650063\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"hetero_t_df3\",\n",
      "      \"learner\": \"lasso_logit\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.01,\n",
      "      \"mean_theta\": 0.4602924382556662,\n",
      "      \"bias\": -0.03970756174433381,\n",
      "      \"rmse\": 0.12124071701842244,\n",
      "      \"mean_se\": 0.11028054144399192,\n",
      "      \"mean_width\": 0.4322997224604483,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.93,\n",
      "      \"cov_se\": 0.01275735082217307,\n",
      "      \"cov_ci_lo\": 0.9049955923885409,\n",
      "      \"cov_ci_hi\": 0.9550044076114592\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"hetero_t_df3\",\n",
      "      \"learner\": \"lasso_logit\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.025,\n",
      "      \"mean_theta\": 0.45107755881037287,\n",
      "      \"bias\": -0.048922441189627186,\n",
      "      \"rmse\": 0.1158377474278551,\n",
      "      \"mean_se\": 0.10242372053132989,\n",
      "      \"mean_width\": 0.40150098448281313,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.9225,\n",
      "      \"cov_se\": 0.013369157602481916,\n",
      "      \"cov_ci_lo\": 0.8962964510991355,\n",
      "      \"cov_ci_hi\": 0.9487035489008645\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"hetero_t_df3\",\n",
      "      \"learner\": \"lasso_logit\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.05,\n",
      "      \"mean_theta\": 0.43809059939128525,\n",
      "      \"bias\": -0.06190940060871474,\n",
      "      \"rmse\": 0.11391446043791295,\n",
      "      \"mean_se\": 0.09439004243136231,\n",
      "      \"mean_width\": 0.3700089663309402,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.8925,\n",
      "      \"cov_se\": 0.01548739406743433,\n",
      "      \"cov_ci_lo\": 0.8621447076278287,\n",
      "      \"cov_ci_hi\": 0.9228552923721712\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"hetero_t_df3\",\n",
      "      \"learner\": \"rf_rf\",\n",
      "      \"strategy\": \"S0_baseline\",\n",
      "      \"winsor_level\": 0.0,\n",
      "      \"mean_theta\": 0.48519235943706873,\n",
      "      \"bias\": -0.014807640562931268,\n",
      "      \"rmse\": 0.1314247223034987,\n",
      "      \"mean_se\": 0.12749163718357462,\n",
      "      \"mean_width\": 0.4997672177596125,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.9525,\n",
      "      \"cov_se\": 0.010635289135702893,\n",
      "      \"cov_ci_lo\": 0.9316548332940223,\n",
      "      \"cov_ci_hi\": 0.9733451667059777\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"hetero_t_df3\",\n",
      "      \"learner\": \"rf_rf\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.005,\n",
      "      \"mean_theta\": 0.48069721535197196,\n",
      "      \"bias\": -0.01930278464802802,\n",
      "      \"rmse\": 0.11593982237149587,\n",
      "      \"mean_se\": 0.11253702625400853,\n",
      "      \"mean_width\": 0.4411451429157134,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.96,\n",
      "      \"cov_se\": 0.009797958971132717,\n",
      "      \"cov_ci_lo\": 0.9407960004165798,\n",
      "      \"cov_ci_hi\": 0.9792039995834201\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"hetero_t_df3\",\n",
      "      \"learner\": \"rf_rf\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.01,\n",
      "      \"mean_theta\": 0.47691012477692646,\n",
      "      \"bias\": -0.02308987522307352,\n",
      "      \"rmse\": 0.11086472230899642,\n",
      "      \"mean_se\": 0.10763395816520656,\n",
      "      \"mean_width\": 0.42192511600760974,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.95,\n",
      "      \"cov_se\": 0.010897247358851688,\n",
      "      \"cov_ci_lo\": 0.9286413951766507,\n",
      "      \"cov_ci_hi\": 0.9713586048233492\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"hetero_t_df3\",\n",
      "      \"learner\": \"rf_rf\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.025,\n",
      "      \"mean_theta\": 0.4632384343427274,\n",
      "      \"bias\": -0.036761565657272614,\n",
      "      \"rmse\": 0.10470865085558113,\n",
      "      \"mean_se\": 0.09890994768777116,\n",
      "      \"mean_width\": 0.38772699493606294,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.9325,\n",
      "      \"cov_se\": 0.0125442965127583,\n",
      "      \"cov_ci_lo\": 0.9079131788349937,\n",
      "      \"cov_ci_hi\": 0.9570868211650063\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"hetero_t_df3\",\n",
      "      \"learner\": \"rf_rf\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.05,\n",
      "      \"mean_theta\": 0.4420967396881409,\n",
      "      \"bias\": -0.0579032603118591,\n",
      "      \"rmse\": 0.10520181459919407,\n",
      "      \"mean_se\": 0.0896915285847564,\n",
      "      \"mean_width\": 0.3515907920522451,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.91,\n",
      "      \"cov_se\": 0.014309088021254182,\n",
      "      \"cov_ci_lo\": 0.8819541874783419,\n",
      "      \"cov_ci_hi\": 0.9380458125216582\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"student_t_df10\",\n",
      "      \"learner\": \"huber_logit\",\n",
      "      \"strategy\": \"S3_robust_nuisance\",\n",
      "      \"winsor_level\": 0.0,\n",
      "      \"mean_theta\": 0.5034062691743489,\n",
      "      \"bias\": 0.003406269174348947,\n",
      "      \"rmse\": 0.09529352080847654,\n",
      "      \"mean_se\": 0.08727329271271879,\n",
      "      \"mean_width\": 0.34211130743385765,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.925,\n",
      "      \"cov_se\": 0.01316956719106592,\n",
      "      \"cov_ci_lo\": 0.8991876483055108,\n",
      "      \"cov_ci_hi\": 0.9508123516944893\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"student_t_df10\",\n",
      "      \"learner\": \"lasso_logit\",\n",
      "      \"strategy\": \"S0_baseline\",\n",
      "      \"winsor_level\": 0.0,\n",
      "      \"mean_theta\": 0.4757777815310562,\n",
      "      \"bias\": -0.024222218468943818,\n",
      "      \"rmse\": 0.09240438883460046,\n",
      "      \"mean_se\": 0.08510901003252816,\n",
      "      \"mean_width\": 0.33362731932751033,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.93,\n",
      "      \"cov_se\": 0.01275735082217307,\n",
      "      \"cov_ci_lo\": 0.9049955923885409,\n",
      "      \"cov_ci_hi\": 0.9550044076114592\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"student_t_df10\",\n",
      "      \"learner\": \"lasso_logit\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.005,\n",
      "      \"mean_theta\": 0.47205704458717873,\n",
      "      \"bias\": -0.027942955412821262,\n",
      "      \"rmse\": 0.09165992801466653,\n",
      "      \"mean_se\": 0.08362407698533611,\n",
      "      \"mean_width\": 0.3278063817825175,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.9325,\n",
      "      \"cov_se\": 0.0125442965127583,\n",
      "      \"cov_ci_lo\": 0.9079131788349937,\n",
      "      \"cov_ci_hi\": 0.9570868211650063\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"student_t_df10\",\n",
      "      \"learner\": \"lasso_logit\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.01,\n",
      "      \"mean_theta\": 0.46871721124599275,\n",
      "      \"bias\": -0.03128278875400723,\n",
      "      \"rmse\": 0.09128312598359851,\n",
      "      \"mean_se\": 0.08244467585716002,\n",
      "      \"mean_width\": 0.3231831293600673,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.915,\n",
      "      \"cov_se\": 0.013944084767384337,\n",
      "      \"cov_ci_lo\": 0.8876695938559267,\n",
      "      \"cov_ci_hi\": 0.9423304061440734\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"student_t_df10\",\n",
      "      \"learner\": \"lasso_logit\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.025,\n",
      "      \"mean_theta\": 0.4593794724568574,\n",
      "      \"bias\": -0.04062052754314257,\n",
      "      \"rmse\": 0.09211234283344442,\n",
      "      \"mean_se\": 0.07970777592549042,\n",
      "      \"mean_width\": 0.31245448162792244,\n",
      "      \"n_reps\": 400,\n",
      "      \"coverage\": 0.91,\n",
      "      \"cov_se\": 0.014309088021254182,\n",
      "      \"cov_ci_lo\": 0.8819541874783419,\n",
      "      \"cov_ci_hi\": 0.9380458125216582\n",
      "    },\n",
      "    {\n",
      "      \"dgp\": \"student_t_df10\",\n",
      "      \"learner\": \"lasso_logit\",\n",
      "      \"strategy\": \"S2_score_winsor\",\n",
      "      \"winsor_level\": 0.05,\n",
      "      \"mean_theta\": 0.44496151811202095,\n",
      "      \"bias\": -0.05503848188797905,\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "bundle = {\n",
    "    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"config\": asdict(CFG),\n",
    "    \"outdir\": os.path.abspath(OUTDIR),\n",
    "    \"files\": {\n",
    "        \"main_mc_raw\": os.path.abspath(os.path.join(OUTDIR, \"main_mc_raw.csv\")),\n",
    "        \"main_mc_summary\": os.path.abspath(os.path.join(OUTDIR, \"main_mc_summary.csv\")),\n",
    "        \"appx_expensive_raw\": os.path.abspath(os.path.join(OUTDIR, \"appx_expensive_raw.csv\")),\n",
    "        \"appx_expensive_summary\": os.path.abspath(os.path.join(OUTDIR, \"appx_expensive_summary.csv\")),\n",
    "    },\n",
    "    \"main_head\": None,\n",
    "    \"appx_head\": None\n",
    "}\n",
    "\n",
    "if SUM_MAIN is not None:\n",
    "    bundle[\"main_head\"] = SUM_MAIN.sort_values([\"dgp\",\"learner\",\"strategy\",\"winsor_level\"]).head(40).to_dict(orient=\"records\")\n",
    "if SUM_APPX is not None:\n",
    "    bundle[\"appx_head\"] = SUM_APPX.sort_values([\"dgp\",\"learner\",\"strategy\",\"winsor_level\"]).head(40).to_dict(orient=\"records\")\n",
    "\n",
    "print(json.dumps(bundle, ensure_ascii=False, indent=2)[:20000])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
